<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>3 patterns for deploying Helm charts with Argo CD</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/05/25/3-patterns-deploying-helm-charts-argocd" /><author><name>Trevor Royer</name></author><id>f29c38b8-072b-4a66-8451-8b36bd422412</id><updated>2023-05-25T07:00:00Z</updated><published>2023-05-25T07:00:00Z</published><summary type="html">&lt;p&gt;Argo CD provides numerous ways to deploy resources from a Helm chart. In this article, you will learn about three patterns used to manage and deploy Helm charts, including when and where to use each pattern in your &lt;a href="https://developers.redhat.com/topics/gitops"&gt;GitOps&lt;/a&gt; environment and the advantages and disadvantages.&lt;/p&gt; &lt;h2&gt;3 patterns for Helm charts&lt;/h2&gt; &lt;p&gt;We will discuss the following three patterns used to manage and deploy Helm charts:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Argo application pointing at a chart in a Helm repo.&lt;/li&gt; &lt;li&gt;Argo application pointing at a chart in a Git repo.&lt;/li&gt; &lt;li&gt;Argo application pointing at a Kustomize folder to render a chart.&lt;/li&gt; &lt;/ol&gt;&lt;h3 id="argo-application-pointing-at-a-chart-in-a-helm-repo"&gt;1. Argo application pointing at a chart in a Helm repo&lt;/h3&gt; &lt;p&gt;The first option for deploying a Helm chart is by referencing a chart that is hosted in a Helm repository.&lt;/p&gt; &lt;p&gt;When deploying a chart from the Argo CD UI, users provide a URL to the Helm repo containing a collection of charts and selects the &lt;strong&gt;Helm&lt;/strong&gt; option in the &lt;strong&gt;Source&lt;/strong&gt; menu. The &lt;strong&gt;Chart&lt;/strong&gt; and &lt;strong&gt;Version&lt;/strong&gt; fields will provide a list of available options from a dropdown menu (Figure 1).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/argo-helm-repo-ui.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/argo-helm-repo-ui.png?itok=6wEMB99e" width="600" height="133" alt="A screenshot of the Argo CD Helm repo configuration form." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The ArgoCD Helm repo configuration page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Once you have entered the a chart in the &lt;strong&gt;Source&lt;/strong&gt; section, a &lt;strong&gt;Helm&lt;/strong&gt; section will become available, allowing you to specify a values file, values in a YAML format, or the default parameters auto-populated by the chart (Figure 2).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/argo-helm-values-ui.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/argo-helm-values-ui.png?itok=bGtjDXZw" width="600" height="303" alt="A screenshot of the Argo CD Helm parameters configuration form." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The ArgoCD Helm parameters configuration page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4 id="advantages"&gt;Advantages and disadvantages of deploying a chart from a Helm repo&lt;/h4&gt; &lt;p&gt;The advantage of deploying a chart directly from a Helm repo is that the UI provides a simple and intuitive user experience. The UI auto-populates the default parameters, presenting configurable options to end users and avoiding mistakes such as misspelled parameter names. This ease of use makes this one of the first options for new users of Argo.&lt;/p&gt; &lt;p&gt;However, this option makes it challenging to troubleshoot or render a helm chart from a development machine with the &lt;code&gt;helm template&lt;/code&gt; command. Any parameters that are populated in the UI are added into the Argo application object which can be manually duplicated on the command line when running &lt;code&gt;helm template&lt;/code&gt;. But this option leaves room for errors and typos. The future option to add a &lt;code&gt;values.yaml&lt;/code&gt; file from a separate Git repo greatly improves the ability to render the chart locally, but it can leave the &lt;code&gt;values.yaml&lt;/code&gt; file orphaned in the Git repo without any additional context, such as the chart repo, name, and version.&lt;/p&gt; &lt;p&gt;Another disadvantage is that this design pattern does not allow for any flexibility or customization to objects deployed in the chart that are not explicitly allowed by the original chart author. For example, if the original author does not include options to set a &lt;code&gt;nodeSelector&lt;/code&gt; in the values, users will not have the ability to set that option in a &lt;code&gt;deployment&lt;/code&gt;.&lt;/p&gt; &lt;h4 id="other-considerations"&gt;Other considerations&lt;/h4&gt; &lt;p&gt;Deploying the chart directly from a Helm repo is best for deploying charts that are well maintained, documented, and require minimal troubleshooting. This option is great for rapid chart deployment and prototyping or set-it-and-forget-it deployments.&lt;/p&gt; &lt;p&gt;The challenges of rendering the chart locally can make this option especially challenging when developing custom charts. In many cases, too much logic and configuration ends up in the Argo application object making it difficult to maintain. This feature in Argo does not currently allow you to utilize another Git repo as a source for the &lt;code&gt;values.yaml&lt;/code&gt; file, which is one of the main challenges of using this pattern for resources that need to be maintained over time.&lt;/p&gt; &lt;h3 id="argo-application-pointing-at-a-chart-in-a-git-repo"&gt;2. Argo application pointing at a chart in a Git repo&lt;/h3&gt; &lt;p&gt;Another option for deploying a Helm chart with Argo is generating a chart and storing it directly in a Git repo. When using this option, users provide a Git repo URL and the path to the &lt;code&gt;Chart.yaml&lt;/code&gt; file. Argo will automatically detect the Helm chart and render the chart when deploying.&lt;/p&gt; &lt;p&gt;Charts stored in the Git repo can be a fully self-contained chart with their own yaml templates or it can take advantage of chart dependencies to deploy charts hosted in a Helm repo or another chart in the same Git repo. Utilizing a chart to configure a dependency and setting parameters with the values.yaml file of that chart are sometimes referred to as a proxy chart.&lt;/p&gt; &lt;p&gt;To utilize a chart stored in a Helm repo, you can provide the dependency information in the &lt;code&gt;Chart.yaml&lt;/code&gt; object as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt;&lt;span class="hljs-attribute"&gt;dependencies&lt;/span&gt;: - &lt;span class="hljs-attribute"&gt;name&lt;/span&gt;: &lt;span class="hljs-string"&gt;"mlflow-server"&lt;/span&gt; &lt;span class="hljs-attribute"&gt;version&lt;/span&gt;: &lt;span class="hljs-string"&gt;"0.5.7"&lt;/span&gt; &lt;span class="hljs-attribute"&gt;repository&lt;/span&gt;: &lt;span class="hljs-string"&gt;"https://strangiato.github.io/helm-charts/"&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To reference another chart located in the same Git repo, you can utilize the &lt;code&gt;file://&lt;/code&gt; protocol in the &lt;code&gt;Chart.yaml&lt;/code&gt; files repository field:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt;&lt;span class="hljs-attribute"&gt;dependencies&lt;/span&gt;: - &lt;span class="hljs-attribute"&gt;name&lt;/span&gt;: &lt;span class="hljs-string"&gt;"my-local-chart"&lt;/span&gt; &lt;span class="hljs-attribute"&gt;version&lt;/span&gt;: &lt;span class="hljs-string"&gt;"0.1.0"&lt;/span&gt; &lt;span class="hljs-attribute"&gt;repository&lt;/span&gt;: &lt;span class="hljs-string"&gt;"file://../my-local-chart/"&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can configure parameters in the local Helm chart by using the &lt;code&gt;values.yaml&lt;/code&gt; file, and Argo will automatically utilize this file when rendering the chart.&lt;/p&gt; &lt;p&gt;Leveraging chart dependencies within the same Git repo allows for a flexible pattern for building out a multi-tiered application deployment to different environments. By creating a simple chart folder structure, such as the following example, users can develop a custom chart for an application deployed to multiple environments and provide configuration differences in the environment-charts &lt;code&gt;values.yaml&lt;/code&gt; file.&lt;/p&gt; &lt;pre&gt; &lt;code&gt;. ├── common-charts │ └── &lt;span class="hljs-keyword"&gt;my&lt;/span&gt;-&lt;span class="hljs-built_in"&gt;application&lt;/span&gt; └── environment-charts ├── dev │ └── &lt;span class="hljs-keyword"&gt;my&lt;/span&gt;-&lt;span class="hljs-built_in"&gt;application&lt;/span&gt; ├── prod │ └── &lt;span class="hljs-keyword"&gt;my&lt;/span&gt;-&lt;span class="hljs-built_in"&gt;application&lt;/span&gt; └── test └── &lt;span class="hljs-keyword"&gt;my&lt;/span&gt;-&lt;span class="hljs-built_in"&gt;application&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt; &lt;h4 id="advantages"&gt;Advantages and disadvantages of deploying a chart from a Git repo&lt;/h4&gt; &lt;p&gt;An advantage of this design pattern provides the most native Helm developer experience and allows developers to take advantage of Helm features, such as &lt;code&gt;helm template&lt;/code&gt; and &lt;code&gt;helm lint&lt;/code&gt; in their local environment, allowing them to easily render the chart locally for testing.&lt;/p&gt; &lt;p&gt;Another advantage of this pattern is when deploying to multiple environments, it enables you to manage the lifecycle of your chart separately in each environment. When utilizing a dependency of a chart stored in a Helm repo, your dev environment can be utilizing &lt;code&gt;v1.1.0&lt;/code&gt; while your prod environment is utilizing &lt;code&gt;v1.0.0&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;A disadvantage of deploying a chart from a Git repo is similar to the Helm repo pattern. If the original author does not provide an option to configure a specific setting, users will not have the ability to set those options.&lt;/p&gt; &lt;p&gt;This option is also limited to only allowing users to provide parameters in the &lt;code&gt;values.yaml&lt;/code&gt; file. Users are not able to create separate &lt;code&gt;values.yaml&lt;/code&gt; files for different environments in a single chart and instead must create a separate chart for each environment they wish to configure.&lt;/p&gt; &lt;p&gt;Another disadvantage is that this pattern can create junk files for a simple deployment that may not be necessary in the final Git repo, such as &lt;code&gt;.helmignore&lt;/code&gt;, &lt;code&gt;Chart.lock&lt;/code&gt; or dependent chart &lt;code&gt;*.tgz&lt;/code&gt; files downloaded locally for testing. Some of these files may be added to the &lt;code&gt;.gitignore&lt;/code&gt; file to reduce clutter in the repo.&lt;/p&gt; &lt;h4 id="other-considerations"&gt;Other considerations&lt;/h4&gt; &lt;p&gt;This option is ideal for getting maximum flexibility when developing a custom charts. The ability to create a simple chart without packaging and storing it in a Helm repo allows for extremely rapid prototyping.&lt;/p&gt; &lt;p&gt;If you manage a chart with a more complex lifecycle, this pattern allows users to maintain different environments with different chart versions and promote changes through the environments in a similar way that images can be promoted to different environments.&lt;/p&gt; &lt;h3 id="argo-application-pointing-at-a-kustomize-overlay-rendering-a-chart"&gt;3. Argo application pointing at a Kustomize folder to render a chart&lt;/h3&gt; &lt;p&gt;The third pattern for deploying Helm charts with Argo is by rendering a Helm chart with Kustomize. In your &lt;code&gt;kustomization.yaml&lt;/code&gt; file, you can provide chart details, including the Helm repo, chart version, and values. This provides similar capabilities to the proxy chart capabilities with the Kustomize tooling.&lt;/p&gt; &lt;p&gt;Values can be provided using &lt;code&gt;valuesFile&lt;/code&gt; to reference a file relative to the &lt;code&gt;kustomization.yaml&lt;/code&gt; file or with &lt;code&gt;valuesInline&lt;/code&gt; where you can directly specify parameters.&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt;&lt;span class="hljs-attribute"&gt;apiVersion&lt;/span&gt;: kustomize.config.k8s.io/v1beta1 &lt;span class="hljs-attribute"&gt;kind&lt;/span&gt;: Kustomization &lt;span class="less"&gt;&lt;span class="hljs-attribute"&gt;helmCharts&lt;/span&gt;: - &lt;span class="hljs-attribute"&gt;name&lt;/span&gt;: mlflow-server &lt;span class="hljs-attribute"&gt;repo&lt;/span&gt;: &lt;span class="hljs-attribute"&gt;https&lt;/span&gt;:&lt;span class="hljs-comment"&gt;//strangiato.github.io/helm-charts/&lt;/span&gt; &lt;span class="hljs-attribute"&gt;version&lt;/span&gt;: &lt;span class="hljs-string"&gt;"0.5.7"&lt;/span&gt; &lt;span class="hljs-attribute"&gt;releaseName&lt;/span&gt;: mlflow-server &lt;span class="hljs-attribute"&gt;namespace&lt;/span&gt;: my-namespace &lt;span class="hljs-attribute"&gt;valuesFile&lt;/span&gt;: values.yaml &lt;span class="hljs-attribute"&gt;valuesInline&lt;/span&gt;: &lt;span class="hljs-attribute"&gt;fullnameOverride&lt;/span&gt;: helloagain&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;From your local environment, you can render the chart by running &lt;code&gt;kustomize build . --enable-helm&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To utilize this option with Argo, you must provide the &lt;code&gt;enable-helm&lt;/code&gt; flag in the Argo CD object definition as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt;&lt;span class="hljs-symbol"&gt;apiVersion:&lt;/span&gt; argoproj.io/v1alpha1 &lt;span class="hljs-symbol"&gt;kind:&lt;/span&gt; ArgoCD &lt;span class="hljs-symbol"&gt;metadata:&lt;/span&gt; &lt;span class="hljs-symbol"&gt; name:&lt;/span&gt; argocd &lt;span class="hljs-symbol"&gt;spec:&lt;/span&gt; &lt;span class="hljs-symbol"&gt; kustomizeBuildOptions:&lt;/span&gt; &lt;span class="hljs-string"&gt;"--enable-helm"&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt; &lt;h4 id="advantages"&gt;Advantages and disadvantages of rendering a Helm chart with Kustomize&lt;/h4&gt; &lt;p&gt;If a team is already heavily relying on Kustomize in their GitOps environments, utilizing Kustomize to render a Helm chart can help to keep a higher consistency with other configurations and reduce the number of tools needed in the repo.&lt;/p&gt; &lt;p&gt;Another advantage is that the combination of Kustomize with Helm also provides a powerful option to patch objects. When leveraging the base/overlays Kustomize pattern, a Helm chart renders in the base layer and additional patches apply in overlays. The ability to apply patches after the Helm chart renders allows you to modify the objects in ways the original chart author did not include.&lt;/p&gt; &lt;p&gt;A disadvantage is that the &lt;code&gt;--enable-helm&lt;/code&gt; flag introduces complexity when attempting to troubleshoot a chart locally. Users may also experience issues when attempting to apply the Kustomize resources with &lt;code&gt;oc apply -k&lt;/code&gt; since the Kustomize tools built into &lt;code&gt;oc&lt;/code&gt;/&lt;code&gt;kubectl&lt;/code&gt; do not support the &lt;code&gt;--enable-helm&lt;/code&gt; flag. Additionally, this option does require modification to the default Argo CD deployment to enable the feature, which some users may not have permission to do.&lt;/p&gt; &lt;p&gt;Another disadvantage when using this pattern, is that once Kustomize has inflated the chart, the objects are treated just like any other yaml objects, and is no longer Helm chart. When utilizing the base/overlays model as previously described, you will lose the ability to control the chart objects using the values parameters.&lt;/p&gt; &lt;h4 id="other-considerations"&gt;Other considerations&lt;/h4&gt; &lt;p&gt;This option is ideal for users that are already heavily relying on Kustomize and don't want to introduce another tool their environment. This option is also fantastic when you do not control the Helm chart that you are attempting to deploy, and you need to modify it in a way that the original author didn't include as a configurable option.&lt;/p&gt; &lt;h2 id="final-thoughts"&gt;Helping you choose a pattern for Helm chart deployment&lt;/h2&gt; &lt;p&gt;In future versions of &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift GitOps&lt;/a&gt;, Argo CD will support the ability to define multiple sources for objects, such as a Helm chart from one repo and a &lt;code&gt;values.yaml&lt;/code&gt; file from another, which could help to eliminate some of the shortcomings of deploying a Helm chart directly from a Helm repo. This feature is discussed in more detail in the article &lt;a href="https://developers.redhat.com/articles/2023/02/20/multiple-sources-argo-cd-applications#"&gt;Multiple sources for Argo CD applications&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;One of the major challenges faced by the GitOps community is finding the correct way to manage resources and a GitOps repo with growing complexity. In many cases, there is no one correct solution, and the three options presented here are valid patterns for deploying and managing Helm charts. Hopefully, the advantages and disadvantages discussed in this article provided insight for the next time you need to choose the best option to incorporate a Helm chart into your environment.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/05/25/3-patterns-deploying-helm-charts-argocd" title="3 patterns for deploying Helm charts with Argo CD"&gt;3 patterns for deploying Helm charts with Argo CD&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Trevor Royer</dc:creator><dc:date>2023-05-25T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus 3.0.4.Final released - Maintenance release</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-3-0-4-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-3-0-4-final-released/</id><updated>2023-05-25T00:00:00Z</updated><content type="html">We released Quarkus 3.0.4.Final, the third maintenance release of our 3.0 release train (as our first public release for 3.0 was 3.0.1.Final). As usual, it contains bugfixes and documentation improvements. It should be a safe upgrade for anyone already using 3.0. If you are not already using 3.0, please refer...</content><dc:creator>Guillaume Smet</dc:creator></entry><entry><title type="html">MicroProfile LRA: A Comprehensive Guide</title><link rel="alternate" href="https://www.mastertheboss.com/eclipse/eclipse-microservices/microprofile-lra-a-comprehensive-guide/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/eclipse/eclipse-microservices/microprofile-lra-a-comprehensive-guide/</id><updated>2023-05-24T21:01:14Z</updated><content type="html">In today’s distributed and microservices-based architectures, ensuring data consistency and coordination across multiple services can be challenging. This is where MicroProfile LRA (Long Running Actions) comes into play. In this tutorial, we will explore the fundamentals of MicroProfile LRA, how to use it effectively, and compare it with other standards such as distributed transactions. What ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">Using MicroProfile LRA in WildFly</title><link rel="alternate" href="https://wildfly.org//news/2023/05/24/MicroProfile-LRA/" /><author><name>Martin Stefanko</name></author><id>https://wildfly.org//news/2023/05/24/MicroProfile-LRA/</id><updated>2023-05-24T00:00:00Z</updated><content type="html">is a specification that defines the protocol and an API for the distributed transactions based on the saga pattern and user-defined compensations. In WildFly 28.0.0.Final, we introduced the integration of which implements this specification. In this guide, we look into how you can enable LRA in your WildFly distribution and how you can use LRA in your applications. OVERVIEW OF THE LRA PROTOCOL We provide only a high-level overview of the LRA protocol in this post. The full overview of the protocol is available at . In LRA, the specification API utilizes annotations from the org.eclipse.microprofile.lra.annotation package. The main annotation is the @LRA which controls the life cycle of the LRA. It’s use might seem similar to the use of @Transactional annotation from JTA, however, the transaction characteristics differ greatly. If you are interested in the comparison of the saga pattern to the ACID transactions, you can find an explanation in this talk from DevoxxUK - . The Narayana implementation utilizes the coordinator orchestration of the LRAs. The LRA coordinator is a standalone service that is responsible for the management operations of the LRAs started in the system. When any LRA participant (user service) wants to start a new LRA, it contacts the LRA coordinator that in turn returns the LRA ID of the newly started LRA that can be propagated by the LRA participant to any other services. When an LRA-aware service receives the LRA ID, it can optionally enlist within the same LRA which is again done by the enlistment call to the coordinator. When the LRA finishes (success or failure), the LRA coordinator is responsible for invocations of the completions or the compensations callbacks of all enlisted LRA participants. ENABLING MICROPROFILE LRA SUBSYSTEMS The integration of the LRA specification is included in two separate subsystems: * microprofile-lra-coordinator - The LRA coordinator responsible for starting, managing, and recovery of the LRAs. * microprofile-lra-participant - The client library utilized in user deployments to participate in the distributed LRAs and define compensation and completition callbacks. REQUIRED EXTENSIONS AND SUBSYSTEMS CONFIGURATION The LRA extensions are not included in the standard configurations included with WildFly application server. They need to be explitcly enabled either in the configuration XML or by using CLI operations: [standalone@localhost:9990 /] /extension=org.wildfly.extension.microprofile.lra-coordinator:add {"outcome" =&gt; "success"} [standalone@localhost:9990 /] /subsystem=microprofile-lra-coordinator:add { "outcome" =&gt; "success", "response-headers" =&gt; { "operation-requires-reload" =&gt; true, "process-state" =&gt; "reload-required" } } [standalone@localhost:9990 /] /extension=org.wildfly.extension.microprofile.lra-participant:add {"outcome" =&gt; "success"} [standalone@localhost:9990 /] /subsystem=microprofile-lra-participant:add { "outcome" =&gt; "success", "response-headers" =&gt; { "operation-requires-reload" =&gt; true, "process-state" =&gt; "reload-required" } } [standalone@localhost:9990 /] reload RUNNING LRA COORDINATOR IN A DOCKER CONTAINER The LRA coordinator is also provided as a standalone Docker image that you can simply run with the following command: $ docker run -p 8080:8080 quay.io/jbosstm/lra-coordinator USING LRA IN USER DEPLOYMENTS The @LRA annotation can be placed on any JAX-RS method to declare that the LRA should be started before the method is entered and closed (finished successfully) when the method ends. By default, if the JAX-RS method returns any of the 4xx or 5xx error HTTP status codes the LRA will be cancelled instead. @LRA @GET @Path("/doInLRA") public Response doInLRA(@HeaderParam(LRA.LRA_HTTP_CONTEXT_HEADER) String lraId) { LOG.info("Work LRA ID = " + lraId); ... When LRA closes successfully, the LRA coordinator calls the completion callback if the participant defined it: @Complete @PUT @Path("/complete") public Response complete(@HeaderParam(LRA.LRA_HTTP_CONTEXT_HEADER) String lraId) { LOG.info("Complete ID = " + lraId); ... Or, in the case of LRA cancel, the compensation callback will be invoked instead: @Compensate @PUT @Path("/compensate") public Response compensate(@HeaderParam(LRA.LRA_HTTP_CONTEXT_HEADER) String lraId) { LOG.info("Compensate ID = " + lraId); ... The full example is available at . If you deploy this application to WildFly (28.0.0+) with both microprofile-lra-coordinator and microprofile-lra-participant subsystems enabled, you can make the following HTTP invocation to see how the coordinator invokes the complete callbacks or the compensation callbacks of the two defined participants: $ curl localhost:8080/lra-participant/lra-participant-1/doInLRA # in WFLY console log 15:14:50,128 INFO [io.xstefank.LRAParticipant1] (default task-1) Work LRA ID = http://localhost:8080/lra-coordinator/lra-coordinator/0_ffff0aca8851_-3330598e_646cbc18_14 15:14:50,158 INFO [io.xstefank.LRAParticipant2] (default task-2) Work LRA ID = http://localhost:8080/lra-coordinator/lra-coordinator/0_ffff0aca8851_-3330598e_646cbc18_14 15:14:50,183 INFO [io.xstefank.LRAParticipant1] (default task-3) Complete ID = http://localhost:8080/lra-coordinator/lra-coordinator/0_ffff0aca8851_-3330598e_646cbc18_14 15:14:50,191 INFO [io.xstefank.LRAParticipant2] (default task-3) Complete ID = http://localhost:8080/lra-coordinator/lra-coordinator/0_ffff0aca8851_-3330598e_646cbc18_14 $ curl "localhost:8080/lra-participant/lra-participant-1/doInLRA?fail=true" # in WFLY console log 15:15:33,516 INFO [io.xstefank.LRAParticipant1] (default task-1) Work LRA ID = http://localhost:8080/lra-coordinator/lra-coordinator/0_ffff0aca8851_-3330598e_646cbc18_1c 15:15:33,531 INFO [io.xstefank.LRAParticipant2] (default task-2) Work LRA ID = http://localhost:8080/lra-coordinator/lra-coordinator/0_ffff0aca8851_-3330598e_646cbc18_1c 15:15:33,543 INFO [io.xstefank.LRAParticipant1] (default task-3) Compensate ID = http://localhost:8080/lra-coordinator/lra-coordinator/0_ffff0aca8851_-3330598e_646cbc18_1c 15:15:33,550 INFO [io.xstefank.LRAParticipant2] (default task-3) Compensate ID = http://localhost:8080/lra-coordinator/lra-coordinator/0_ffff0aca8851_-3330598e_646cbc18_1c You can also always check the currently active LRAs with a direct call to the coordinator API: $ curl localhost:8080/lra-coordinator/lra-coordinator []% CONCLUSION In this post, we showed you how to configure and use the MicroProfile LRA specification in your WildFly applications. LRA provides a very broad feature set which we can’t cover here. If you are interested in learning more, you can find the full specification at .</content><dc:creator>Martin Stefanko</dc:creator></entry><entry><title>Podman Desktop 1.0: Local container development made easy</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/05/23/podman-desktop-now-generally-available" /><author><name>Stevan Le Meur</name></author><id>40318020-209c-48e6-8f98-55b451b02daf</id><updated>2023-05-23T13:45:50Z</updated><published>2023-05-23T13:45:50Z</published><summary type="html">&lt;p&gt;As containerization continues to gain popularity in the world of enterprise software development, there is also growing demand for tools and technologies that make &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; management more accessible and efficient. One such tool is Podman Desktop, which provides a user-friendly interface for managing containers and working with &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; from a local machine (Figure 1).&lt;/p&gt; &lt;p&gt;After months of hard work, we are excited to announce the general availability (GA) of Podman Desktop 1.0. Let's explore what Podman Desktop is and why it can be advantageous for enterprise developers.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/podman-desktop-ga.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/podman-desktop-ga.png?itok=04C__0YE" width="600" height="351" alt="Screenshots of various Podman Desktop interface elements" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The Podman Desktop interface.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Why use Podman Desktop?&lt;/h2&gt; &lt;p&gt;Podman Desktop is a container management tool that lets developers easily create, manage, and deploy containers on their local machine. Podman Desktop downloads, installs, and abstracts away the configuration of the underlying environment. This makes it a lightweight and efficient option for container management without the overhead of having to administer everything locally.&lt;/p&gt; &lt;h3&gt;Easily manage multiple containers&lt;/h3&gt; &lt;p&gt;The main advantage of using a UI like Podman Desktop for container management, especially for enterprise developers, is that it simplifies the process of working with containers. You can easily view and manage all containers in one place rather than having to remember and type out complex command-line commands. This saves time and reduces the risk of errors when managing multiple containers or complex container configurations.&lt;/p&gt; &lt;h3&gt;Onboard developers faster&lt;/h3&gt; &lt;p&gt;Another advantage of using Podman Desktop is that it can help developers who are new to containerization get started more easily. The user-friendly interface and simplified management process make it easier for developers who might be intimidated by the command-line interface of other container management tools to get started with containerization. This can help organizations onboard new developers more quickly and reduce the learning curve for containerization.&lt;/p&gt; &lt;h3&gt;Work natively with Kubernetes&lt;/h3&gt; &lt;p&gt;For developers interested in Kubernetes or targeting it as a deployment platform, Podman Desktop provides the ability to natively work with Kubernetes objects, which helps to gradually and naturally transition from containers to Kubernetes. Podman Desktop also provides an out-of-the-box Kubernetes environment based on Kind. This means that developers can create and test applications in an environment that closely mirrors production, preventing configuration changes between development and production and ensuring a smooth transition from one environment to another.&lt;/p&gt; &lt;h2&gt;Key features&lt;/h2&gt; &lt;p&gt;Podman Desktop includes many features that streamline container workflows, ensuring a smooth and efficient developer experience. &lt;/p&gt; &lt;h3&gt;Podman and Kubernetes Local&lt;/h3&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;Install and run anywhere: Windows, macOS, and &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Configure and install via Podman, Kind, &lt;a href="https://developers.redhat.com/products/openshift-local/overview"&gt;Red Hat OpenShift Local&lt;/a&gt;, &lt;a href="https://developers.redhat.com/developer-sandbox" target="_blank"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Keep Podman and other dependencies up to date&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Containers and pods&lt;/h3&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;Build, run, manage, and debug containers and pods&lt;/li&gt; &lt;li aria-level="2"&gt;Run pods with or without Kubernetes&lt;/li&gt; &lt;li aria-level="2"&gt;Use the built-in terminal to ssh into containers&lt;/li&gt; &lt;li aria-level="2"&gt;Manage multiple container engines&lt;/li&gt; &lt;li aria-level="2"&gt;Manage volumes&lt;/li&gt; &lt;li aria-level="2"&gt;Compatabile with Docker Compose&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Kubernetes&lt;/h3&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;Play Kubernetes YAML&lt;/li&gt; &lt;li aria-level="2"&gt;Generate Kubernetes YAML from Pods&lt;/li&gt; &lt;li aria-level="2"&gt;Podify and Kubify: Convert containers to pods and Kubernetes&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Enterprise readiness&lt;/h3&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;VPN and proxies configuration&lt;/li&gt; &lt;li aria-level="2"&gt;Image registry management &lt;ul&gt;&lt;li aria-level="3"&gt;Configure multiple OCI registries&lt;/li&gt; &lt;li aria-level="3"&gt;Pull, tag, and push images&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;AirGapped installation&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Bridge between local and remote environments&lt;/h3&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;Connect and deploy to remote OpenShift clusters&lt;/li&gt; &lt;li aria-level="2"&gt;Enable remote managed services locally&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Extensibility&lt;/h3&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;Possibility to extend the container engines or Kubernetes providers&lt;/li&gt; &lt;li aria-level="2"&gt;Extension points to add actions, menus, configurations and enrich the UI with specific capabilities&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;From OpenShift Local to production&lt;/h2&gt; &lt;p&gt;One of the unique features of Podman Desktop is its integration with &lt;a href="https://developers.redhat.com/products/openshift-local/overview"&gt;Red Hat OpenShift Local&lt;/a&gt; (Figure 2), which lets users develop and test applications locally using the same container images and environment as they would in a production  environment on &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;. This means you can ensure that your applications will run smoothly in an OpenShift environment before deploying them.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/podman-desktop-openshift-local.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/podman-desktop-openshift-local.png?itok=y-UGHnMb" width="600" height="436" alt="podman-desktop-openshift-local-integration" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Initializing OpenShift Local in Podman Desktop.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;OpenShift Local is essentially a single-node OpenShift cluster that runs locally on the developer's machine. It is based on the same technology as OpenShift and provides a consistent environment for developing and testing applications.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;[ Learn more: &lt;a href="https://developers.redhat.com/articles/2022/05/10/whats-new-openshift-local-20"&gt;What’s new in OpenShift Local 2.0&lt;/a&gt; ]&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Podman Desktop 1.0 includes an extension for OpenShift Local, which you can install from the dashboard (Figure 3) or Settings (Figure 4).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-local-podman-desktop-extension.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-local-podman-desktop-extension.png?itok=GKTvGcPl" width="600" height="368" alt="Installing the OpenShift Local extension from the dashboard in Podman Desktop." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: Installing the OpenShift Local extension from the dashboard in Podman Desktop.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/podman-desktop-openshift-local-settings.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/podman-desktop-openshift-local-settings.png?itok=srcXSYsl" width="600" height="436" alt="Installing the OpenShift Local extension from the Settings page in Podman Desktop." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: Installing the OpenShift Local extension from the Settings page in Podman Desktop.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Once installed, the extension provides you the ability to configure the different presets you can use for OpenShift Local:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;strong&gt;Single-node OpenShift&lt;/strong&gt; powered by OpenShift Container Platform &lt;ul&gt;&lt;li aria-level="2"&gt;Full services set&lt;/li&gt; &lt;li aria-level="2"&gt;Complete and more resource-intensive&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Light and optimized&lt;/strong&gt; (experimental) powered by Microshift &lt;ul&gt;&lt;li aria-level="2"&gt;Minimal services set&lt;/li&gt; &lt;li aria-level="2"&gt;Fast and lightweight&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;With Podman Desktop, you can ease the transition of an application from a local environment to a remote production OpenShift environment.&lt;/p&gt; &lt;h2&gt;Local Kubernetes with Kind&lt;/h2&gt; &lt;p&gt;If you are looking for an even lighter local runtime, Podman Desktop offers the option to use &lt;a href="https://podman-desktop.io/docs/kubernetes/kind"&gt;Kind&lt;/a&gt; as an alternative container orchestration tool. The use of Kind provides several benefits for developers who are striving to create a development environment that closely mirrors production.&lt;/p&gt; &lt;p&gt;One key advantage of using Kind is that it allows developers to create a multi-node Kubernetes cluster on their local machine. Unlike Docker Compose, which is designed for single-node environments, Kind provides a more realistic environment for testing applications that will be deployed on multiple nodes in production. With Kind, developers can simulate a more complex environment and ensure their applications are ready for production deployment.&lt;/p&gt; &lt;p&gt;Kind creates Kubernetes clusters as containers, which means that developers can easily test their applications with the latest version of Kubernetes without having to install and configure it manually. Kind also simplifies the process of spinning up and tearing down Kubernetes clusters, which can save developers time and reduce the risk of configuration errors.&lt;/p&gt; &lt;h3&gt;Creating Kind clusters in Podman Desktop&lt;/h3&gt; &lt;p&gt;To create a Kind cluster from Podman Desktop, go into the &lt;strong&gt;Settings → Resources&lt;/strong&gt; page; you'll find a section enabling you to configure a cluster (see Figure 5).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ingress-controller-kind-podman.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/ingress-controller-kind-podman.png?itok=Dt1-T6w-" width="600" height="419" alt="Configuring a Kind cluster from the Podman Desktop Resources page." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: Configuring a Kind cluster from the Podman Desktop Resources page.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;You can choose a name for the cluster and specify the ports to be used by the cluster. You can also set up an Ingress controller (with the project Contour), as shown in Figure 6.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/podman-desktop-kind-cluster.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/podman-desktop-kind-cluster.png?itok=D-yhT9Cc" width="600" height="419" alt="Configuring a Kind cluster in Podman Desktop" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Configuring the cluster and enabling an Ingress controller in Podman Desktop.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Once the cluster is up and running, it will be your default kubecontext. You can interact with the cluster either from Podman Desktop or the other tools you are using, such as kubectl. If you need to interact with the cluster, you can open the terminal directly from within Podman Desktop.&lt;/p&gt; &lt;p&gt;Using Kind with Podman Desktop allows developers to ensure their local development environment closely mirrors their production environment. By using the same container orchestration tool and environment as production, you can avoid issues that might arise when deploying applications to production, such as configuration differences or compatibility issues. Using Kind with Podman Desktop creates a more efficient and reliable development process that ultimately leads to more successful production deployments.&lt;/p&gt; &lt;h2&gt;Developer Sandbox for Red Hat OpenShift extension&lt;/h2&gt; &lt;p&gt;We also added an extension for the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;, which you can install from the dashboard or the Settings (Figure 7). The Developer Sandbox for Red Hat OpenShift is a free, cloud-based OpenShift environment for developers to create, build, and deploy applications on OpenShift at no cost. With Podman Desktop, you can easily connect to the Developer Sandbox from your local machine and deploy your applications to the cloud-based environment.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/podman-desktop-developer-sandbox.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/podman-desktop-developer-sandbox.png?itok=tTrUFgIL" width="600" height="467" alt="Accessing the Developer Sandbox for Red Hat OpenShift using the extension for Podman Desktop." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 7: Accessing the Developer Sandbox for Red Hat OpenShift using the extension for Podman Desktop.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;To use Podman Desktop with the Developer Sandbox, you must first &lt;a href="https://developers.redhat.com/articles/2023/03/30/how-access-developer-sandbox-red-hat-openshift"&gt;sign up for a free account&lt;/a&gt; and create a new project in the OpenShift web console. You can then use Podman Desktop to build and test your application locally, using the same container images and environment as you would in production. Once the application is ready for deployment, you can use Podman Desktop to push the container images to the OpenShift registry and deploy your application to the OpenShift environment.&lt;/p&gt; &lt;p&gt;Using Podman Desktop with the Developer Sandbox for Red Hat OpenShift provides several benefits for enterprise developers. It lets you test your applications in a managed Kubernetes environment without having to set up and manage your own infrastructure. It also provides a consistent environment for testing and deployment, which can help reduce the risk of configuration errors and compatibility issues.&lt;/p&gt; &lt;h2&gt;What’s next?&lt;/h2&gt; &lt;p&gt;We plan to improve Podman Desktop with more capabilities to help you work with containers and facilitate the transition from containers to Kubernetes. We are also planning to extend the support of Kubernetes objects, enabling you to create, run, debug, and more easily manage all different components of your applications.&lt;/p&gt; &lt;p&gt;For developers targeting OpenShift, you'll see more tools integrated with Podman Desktop that make it smoother and more efficient to build your application locally and run/debug it in an environment consistent with production. &lt;/p&gt; &lt;h2&gt;More information&lt;/h2&gt; &lt;p&gt;Podman Desktop continues its momentum, and we are excited about the road ahead. Visit &lt;a href="https://podman-desktop.io"&gt;podman-desktop.io&lt;/a&gt; to download the tool and learn more about the project.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Read more about Podman Desktop on Red Hat Developer: &lt;a href="https://developers.redhat.com/articles/2023/03/01/podman-desktop-introduction"&gt;What is Podman Desktop? A developer's introduction&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Visit the Podman website: &lt;a href="http://podman.io"&gt;podman.io&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Explore the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/containers/podman-desktop"&gt;Support us by giving a ⭐️&lt;/a&gt;!&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/05/23/podman-desktop-now-generally-available" title="Podman Desktop 1.0: Local container development made easy"&gt;Podman Desktop 1.0: Local container development made easy&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Stevan Le Meur</dc:creator><dc:date>2023-05-23T13:45:50Z</dc:date></entry><entry><title>A developer’s guide to Red Hat Developer Hub and Janus</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/05/23/developers-guide-red-hat-developer-hub-and-janus" /><author><name>Ian Lawson, Yaina Williams</name></author><id>bfe4f902-f799-400b-a548-bc094ce78c41</id><updated>2023-05-23T13:00:00Z</updated><published>2023-05-23T13:00:00Z</published><summary type="html">&lt;p&gt;This article introduces the new &lt;a href="https://developers.redhat.com/products/developer-hub/overview"&gt;Red Hat Developer Hub&lt;/a&gt; and Janus project to address the challenges IT organizations face in the development process. A developer’s work can be fraught with disparate development systems and distributed teams, and organizations with multiple development teams often struggle with competing priorities, diverse tools and technologies, and establishing best practices.&lt;/p&gt; &lt;p&gt;These challenges make it difficult to quickly start development and adhere to multiple security and compliance standards. A unified platform that can consolidate these elements of the development process and foster internal collaboration will enable development teams to focus on rapidly enhancing code and functionality to efficiently build high-quality software.&lt;/p&gt; &lt;h2&gt;Simplifying the inner loop for developers&lt;/h2&gt; &lt;p&gt;Simplifying the inner and outer loop model is also an important part of improving the development process. The article &lt;a href="https://developers.redhat.com/articles/2022/12/16/standardizing-application-delivery-openshift#"&gt;Standardizing application delivery with OpenShift&lt;/a&gt; explains the concept and purpose of dividing the development process into two loops. In the inner loop, the developer works on the code. In the outer loop, developers push the code to version control for automation, testing, and deployment until it is ready for release. Developers need a simple inner loop so that they can focus on finding software solutions, not configuring tools.&lt;/p&gt; &lt;p&gt;Developers need a single place, like a hub, where they can find resources, utilize and generate shareable components, and follow Golden Path templates&lt;em&gt; &lt;/em&gt;(templated paths to quick and easy software development). Read on to learn about the new Red Hat Developer Hub and Janus project, and how they simplify the developer workflow.&lt;/p&gt; &lt;h2&gt;Overview of Backstage and Project Janus&lt;/h2&gt; &lt;p&gt;Red Hat Developer Hub is our enterprise-grade, supported version of &lt;a href="https://backstage.io/"&gt;Backstage&lt;/a&gt;, an open source framework (provided by Spotify) for building developer portals. Engineering teams can use Red Hat Developer Hub to reduce friction and frustration and boost their productivity, giving their organization a competitive advantage.&lt;/p&gt; &lt;p&gt;We have preloaded all the necessary Red Hat plug-ins, including a variety of technology and tools that reduce developer cognitive load and support self service, while maintaining context and underlying technologies continuously maintained and improved by platform teams.&lt;/p&gt; &lt;p&gt;Our new initiative, Project Janus, has developed and enhanced the Golden Path templates, Backstage platform, and plug-ins.&lt;/p&gt; &lt;h3&gt;6 Red Hat Plug-ins for Backstage&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/plugins-for-backstage/overview"&gt;Red Hat Plug-ins for Backstage&lt;/a&gt; work in tandem with Red Hat Developer Hub and pre-existing customer installations of Backstage, extending functionality and improving the overall experience. These 6 plug-ins are the supported version of the community plug-ins:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Authentication and Authorization with Keycloak:&lt;/strong&gt; Load users and groups from Keycloak to Backstage, enabling use of multiple authentication providers applied to Backstage entities.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Multicluster View with Open Cluster Manager (OCM):&lt;/strong&gt; This plug-in provides a multicluster view from Open Cluster Manager’s MultiClusterHub and MultiCluster Engine in Backstage.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Container Image Registry for Quay:&lt;/strong&gt; The &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; image registry for Quay improves the integration and speed of interactions with Quay registries by providing a view into the container image details. This includes Common Vulnerabilities and Exposures (CVEs) associated with deployed images.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Application Topology for Kubernetes:&lt;/strong&gt; Consistently visualize relationships and real-time status of applications and workloads deployed to any &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; target, including &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Pipelines with Tekton:&lt;/strong&gt; This plug-in provides details of all Tekton Pipelines and their status across all services.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;GitOps with Argo CD:&lt;/strong&gt; Track the health and status of Argo CD and monitor services inside Backstage.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Streamline onboarding with Golden Path templates&lt;/h2&gt; &lt;p&gt;Red Hat Developer Hub provides Golden Path templates that are essential for fast-tracking development and ensuring organization and consistency. These templates are referred to as &lt;strong&gt;golden&lt;/strong&gt; because they provide gold-standard best practices for developers to follow so your code will be coherent, scalable, and maintainable.&lt;/p&gt; &lt;p&gt;You can streamline application and developer onboarding with Golden Path templates. Golden Paths provide pre-architected and supported approaches to building and deploying a particular piece of software without having to learn all the details of the technology used.&lt;/p&gt; &lt;p&gt;Templates enable self-service for developers. They also&lt;strong&gt; &lt;/strong&gt;provide the best pathway to fix bugs or implement features, enabling developers to speed up the process, thereby making your organization more competitive.&lt;/p&gt; &lt;h2&gt;The two sides of Red Hat Developer Hub&lt;/h2&gt; &lt;p&gt;We will explain Red Hat Developer Hub by describing it from two sides—consumption and configuration—and two points of view (i.e., the developer and the &lt;a href="https://developers.redhat.com/topics/devops"&gt;DevOps&lt;/a&gt; administrator.)&lt;/p&gt; &lt;p&gt;From a consumption perspective, Red Hat Developer Hub perfectly matches the functionality needed for the developer as part of the inner loop. For the first time, a developer has a single place to find everything, from links, integrated development environments (IDEs), and GitHub repos, to documentation and components catalogs added to applications.&lt;/p&gt; &lt;h3&gt;How Red Hat Developer Hub benefits developers&lt;/h3&gt; &lt;p&gt;Red Hat Developer Hub provides a single place for a developer to work. Finally, there’s a hub for all things a developer needs, such as resources, clusters, and templates. Red Hat Developer Hub provides complete coverage of the inner loop, IDE, direction interaction, and authentication to GitHub.&lt;/p&gt; &lt;p&gt;Developers must understand the complexity of the various tools they use. Learning numerous toolsets as well as the ins and outs of the frameworks, technologies, and components of their organization can be time consuming. The primary goal of Red Hat Developer Hub is to ease the development process and provide an aggregated toolset that reduces the mental overhead of context switching and searching for the core components they need.&lt;/p&gt; &lt;p&gt;Red Hat Developer Hub provides a wizard and template-driven experience for end developers. This makes it very easy to build complex systems from multiple components, including Git source-driven deployments to systems such as Kubernetes and OpenShift. In addition, the provisioning of these components simplifies the knowledge the developer needs. With a couple of clicks and text entry points, developers can convert a template to a running application component without knowing the convoluted technology beneath it.&lt;/p&gt; &lt;p&gt;This gives developers more time to spend on developing rather than configuring development environments and components. Not only is the developer presented with a rich set of components from which to choose, but system administrators can configure these components.&lt;/p&gt; &lt;h3&gt;How Red Hat Developer Hub benefits administrators&lt;/h3&gt; &lt;p&gt;Red Hat Developer Hub is built on the Janus open source project, which extends the Backstage open source project, providing a highly configurable and secure development portal and catalog to control which components can be built together. Red Hat Developer Hub extends the functionality through a set of predefined supported plug-ins providing extensions and components to ease the developer's path as they design and build composite applications.&lt;/p&gt; &lt;p&gt;Using code-as-config, administrators can control exactly what developers can interact with and at what level, providing a simple to use and simple to configure mechanism for providing developers with a single point for all things development.&lt;/p&gt; &lt;p&gt;Red Hat Developer Hub also provides a highly configurable authentication model, allowing integration with providers such as GitHub and Keycloak. Administrators can configure authentication methods, templates (i.e., multi-component quick starts and API definitions), and the base definitions. This is a sophisticated tool for building organizational developer portals.&lt;/p&gt; &lt;h2&gt;Red Hat Developer Hub increases productivity and more&lt;/h2&gt; &lt;p&gt;Red Hat Developer Hub is designed to significantly improve engineering productivity for IT organizations, enabling development teams to focus on what really matters—writing high-quality code and accelerating application delivery to give organizations a competitive advantage.&lt;/p&gt; &lt;p&gt;Learn more by visiting the &lt;a href="http://developers.redhat.com/products/developer-hub"&gt;Red Hat Developer Hub&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/05/23/developers-guide-red-hat-developer-hub-and-janus" title="A developer’s guide to Red Hat Developer Hub and Janus"&gt;A developer’s guide to Red Hat Developer Hub and Janus&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Ian Lawson, Yaina Williams</dc:creator><dc:date>2023-05-23T13:00:00Z</dc:date></entry><entry><title type="html">WildFly 28.0.1 is released!</title><link rel="alternate" href="https://wildfly.org//news/2023/05/23/WildFly2801-Released/" /><author><name>Farah Juma</name></author><id>https://wildfly.org//news/2023/05/23/WildFly2801-Released/</id><updated>2023-05-23T00:00:00Z</updated><content type="html">WildFly 28.0.1.Final is now available . It’s been about five weeks since the WildFly 28 release, so we’ve done a small bug fix update, WildFly 28.0.1. This includes an update to WildFly Preview. The following issues were resolved in 28.0.1: BUGS * [] - todo-backend QS has outdated Readme instructions * [] - Add missing org.jboss.vfs to RESTEasy Spring deployments * [] - todo-backend Readme OpenShift instructions results in a non-functional QS app * [] - LRA causes a failure in the ContextPropagationTestCase * [] - ExpirationMetaData.isExpired() test does not conform to logic in LocalScheduler * [] - Add java.base/java.net package to recommended client side JPMS settings * [] - The JaxrsIntegrationProcessor should not attempt to get the RESTEasy configuration when not a REST deployment. COMPONENT UPGRADES * [] - Upgrade to Smallrye opentelemetry 2.3.2 * [] - Upgrade RESTEasy to 6.2.4.Final * [] - Upgrade xalan to 2.7.3 (CVE-2022-34169) * [] - Upgrade jose4j to 0.9.3 * [] - WildFly Core to 20.0.2.Final Issues resolved in the WildFly Core update included with WildFly 28.0.1 were: BUGS * [] - Changes to json-formatter meta-data never take effect * [] - module java.base does not "opens java.net" to unnamed module TASKS * [] - Add back the org.jboss.vfs module as a dependency on deployments COMPONENT UPGRADES * [] - CVE-2022-1259 Upgrade Undertow to 2.3.6.Final Enjoy!</content><dc:creator>Farah Juma</dc:creator></entry><entry><title type="html">Using Visual Studio to develop and manage WildFly</title><link rel="alternate" href="https://www.mastertheboss.com/eclipse/jboss-tools/using-visual-studio-to-develop-and-manage-wildfly/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/eclipse/jboss-tools/using-visual-studio-to-develop-and-manage-wildfly/</id><updated>2023-05-22T09:13:15Z</updated><content type="html">Visual Studio Community Edition is completely free IDE for individual developers. Despite being free, it provides a rich set of features and capabilities comparable to the paid editions of Visual Studio. In this article we will learn how to use it to develop applications on top of WildFly application Server. Harness the Advantages of Visual ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>How to use OpenShift Data Science for fraud detection</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/05/22/how-use-openshift-data-science-fraud-detection" /><author><name>Swati Kale</name></author><id>5502a392-3021-4849-9d81-77714a7af992</id><updated>2023-05-22T07:00:00Z</updated><published>2023-05-22T07:00:00Z</published><summary type="html">&lt;p&gt;The problem of detecting fraudulent transactions is intriguing for a data scientist. However, the overhead from setting up the technologies around it can be cumbersome. This is where &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-data-science"&gt;Red Hat OpenShift Data Science&lt;/a&gt;, along with &lt;a href="https://www.starburst.io/"&gt;Starburst&lt;/a&gt; and Intel &lt;a href="https://docs.openvino.ai/latest/home.html"&gt;OpenVino&lt;/a&gt;, come to the rescue. Now data scientists can focus on what they do best, model training and crafting; and OpenShift Data Science will do what we do best, providing the tools with the least overhead. &lt;/p&gt; &lt;p&gt;This article will cover detecting fraudulent transactions in a financial institution on Red Hat OpenShift Data Science.&lt;/p&gt; &lt;h2&gt;Workflow for credit card fraud detection&lt;/h2&gt; &lt;p&gt;Credit card fraud is a significant problem in the finance industry. Fraudsters can steal credit card information and use it to make unauthorized purchases. Fraud detection systems can monitor credit card transactions and identify suspicious activities, such as large transactions or transactions in unusual locations, and flag them for further investigation.&lt;/p&gt; &lt;p&gt;Building an effective fraud detection system using machine learning requires careful data collection, feature engineering, model selection, training and validation, deployment, monitoring, and updating to ensure that the system remains effective over time.&lt;/p&gt; &lt;p&gt;The diagram in Figure 1 shows the typical workflow for building and deploying machine learning models for detecting credit card payment fraud.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/workflow_1.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/workflow_1.png?itok=zQ3ra5xb" width="512" height="57" alt="This diagram shows the typical workflow for building and deploying machine learning models for detecting credit card payment fraud." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: This diagram shows the typical workflow for building and deploying machine learning models for detecting financial fraud.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Overview of the fraud detection solution&lt;/h2&gt; &lt;p&gt;Figure 2 shows how to use the OpenShift Data Science platform to deploy an agile solution for detecting fraudulent credit card payment.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/solution.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/solution.png?itok=4TJY-qMF" width="512" height="310" alt="A diagram of the solution steps using the OpenShift Data Science platform to detect fraudulent credit card payment." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The solution steps using the OpenShift Data Science platform to detect fraudulent credit card payment.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The steps in the diagram are as follows:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;The data scientist uploads data to Amazon S3.&lt;/li&gt; &lt;li aria-level="1"&gt;Starburst Enterprise is connected to Amazon S3.&lt;/li&gt; &lt;li aria-level="1"&gt;The data scientist uses the query editor in Starburst to preprocess the data and visualize the dataset.&lt;/li&gt; &lt;li aria-level="1"&gt;The cleaned data is uploaded back to Amazon S3 via Starburst.&lt;/li&gt; &lt;li aria-level="1"&gt;Next, the data scientist creates a data science project within OpenShift Data Science which enables them to launch JupyterLab along with specific dependencies.&lt;/li&gt; &lt;li aria-level="1"&gt;Retrieves the cleaned data from Amazon S3. Using the data, they train machine learning models and upload them back to Amazon S3.&lt;/li&gt; &lt;li aria-level="1"&gt;The trained models are then served by the OpenVINO Model Server.&lt;/li&gt; &lt;li aria-level="1"&gt;Finally, the models are deployed for fraud detection.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;What is Red Hat OpenShift Data Science?&lt;/h2&gt; &lt;p&gt;Red Hat OpenShift Data Science is a platform for developing, deploying, and managing machine learning workflows and models in a containerized environment. It is built on top of the Red Hat OpenShift Container Platform and provides a suite of tools and services for ML workflows, including data preparation, model training, and model deployment. Read more about OpenShift Data Science in the article, &lt;a href="https://developers.redhat.com/blog/2021/04/27/4-reasons-youll-love-using-red-hat-openshift-data-science"&gt;4 reasons you’ll love using OpenShift Data Science&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;OpenShift Data Science is fully integrated with AI/ML tools, including &lt;a href="https://blog.jupyter.org/jupyterlab-is-ready-for-users-5a6f039b8906"&gt;JupyterLab&lt;/a&gt; with predefined notebook images for launching notebooks with access to core AI/ML libraries and frameworks like &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt;. It provides a single interface for managing and implementing all ML steps, including model deployment and training, and is backed by local storage for saving tasks for later use.&lt;/p&gt; &lt;p&gt;In our workflow, we created a data connection to Amazon S3 for adding data to the project. OpenShift Data Science is also integrated with Kserve ModelMesh Serving, which provides out-of-the-box integration with model servers and allows selecting the model server and data connection. The user can view the current status of deployed models and their inference endpoints.&lt;/p&gt; &lt;p&gt;We configured the OpenVINO Model Server, which allows for easy deployment and management of pre-trained deep learning models in production environments. It provides a flexible and scalable platform for deploying deep learning models with RESTful APIs, making it easy to integrate the models with applications.&lt;/p&gt; &lt;h2&gt;Why we use Starburst and Amazon S3&lt;/h2&gt; &lt;p&gt;Starburst Enterprise provides a powerful, user-friendly interface for managing Trino clusters, monitoring query performance, and identifying bottlenecks. It is a popular tool for organizations that use Trino for distributed SQL query processing and require a comprehensive interface for managing their Trino clusters. It unlocks access to data where it lives, no data movement required, giving your teams fast and accurate access to more data for analysis using query editor.&lt;/p&gt; &lt;p&gt;We use Amazon S3 for storing the datasets and trained models. The user can make use of the Amazon S3 in data collection, preprocessing data, and model training phase.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;OpenShift Data Science sandbox&lt;/li&gt; &lt;li aria-level="1"&gt;Starburst Enterprise license&lt;/li&gt; &lt;li aria-level="1"&gt;Starburst Operator installed&lt;/li&gt; &lt;li aria-level="1"&gt;Read and write access to Amazon S3 bucket&lt;/li&gt; &lt;li aria-level="1"&gt;Access to the original dataset&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;The environment setup&lt;/h2&gt; &lt;p&gt;You can find guidance for setting up the environment by following these links:&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science/download"&gt;Set up your Red Hat OpenShift Data Science environment&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;If you haven’t already, you can find information about getting an instance of Red Hat OpenShift Data Science on the &lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science/download"&gt;developer page&lt;/a&gt;. You can spin up your own account on the free OpenShift Data Science Sandbox or learn about installing on your OpenShift cluster.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/RHEcosystemAppEng/rhods-fraud-detection/blob/master/Starburst.md"&gt;Set up Starburst operator on OpenShift Data Science&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/RHEcosystemAppEng/rhods-fraud-detection/blob/master/Starburst.md"&gt;Connect Starburst to Amazon S3 and launch Starburst Query Editor&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/RHEcosystemAppEng/rhods-fraud-detection"&gt;Try out the fraud detection use case on OpenShift Data Science&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Watch the demo video presented by &lt;strong&gt;Suvro Ghosh&lt;/strong&gt; (creator):&lt;/p&gt; &lt;div class="video-embed-field-provider-youtube video-embed-field-responsive-video"&gt; &lt;/div&gt; &lt;h2&gt;OpenShift Data Science simplifies fraud detection&lt;/h2&gt; &lt;p&gt;Red Hat OpenShift Data Science provides a fully supported environment in which to rapidly develop, train, and test AI/ML models in the public cloud before deploying in production. This use case can be extended by bringing your algorithm for fraud detection and model framework using the OpenShift Data Science ecosystem. Feel free to comment below if you have questions. We welcome your feedback!&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/05/22/how-use-openshift-data-science-fraud-detection" title="How to use OpenShift Data Science for fraud detection"&gt;How to use OpenShift Data Science for fraud detection&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Swati Kale</dc:creator><dc:date>2023-05-22T07:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.38.0 released!</title><link rel="alternate" href="https://blog.kie.org/2023/05/kogito-1-38-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2023/05/kogito-1-38-0-released.html</id><updated>2023-05-22T05:42:46Z</updated><content type="html">We are glad to announce that the Kogito 1.38.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Data Index addons that allow running indexing capabilities as part of Kogito runtimes, incorporate now the interaction with the Job Service embedded Quarkus extension. * Rocksdb persistence quarkus add-on * Serverless Workflow embedded executor dependency list has been substantially reduced. * Added support for full GVK to Knative custom function * Added support for existing “quarkus.flyway.locations” values  For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.28.0 artifacts are available at the . A detailed changelog for 1.38.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry></feed>
